{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the results of cross validation for Scikit-Learn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from faculty_xval.utilities import most_recent_xval_dirs\n",
    "from faculty_xval.validation import jobs_cross_validator_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_DIR = \"/project/{}/temp/\".format(\n",
    "    os.environ[\"USER_NAME\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate directory for most recent cross validation.\n",
    "xval_dir = most_recent_xval_dirs(REFERENCE_DIR)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload instance of JobsCrossValidator.\n",
    "cross_validator = jobs_cross_validator_from_json(\n",
    "    os.path.join(xval_dir, \"validator.json\")\n",
    ")\n",
    "if cross_validator.model_type != \"sklearn\":\n",
    "    raise TypeError(\"Model type must be Scikit-Learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the results of cross validation.\n",
    "_, indices_test, predictions = cross_validator.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the target data.\n",
    "with open(\n",
    "    os.path.join(\n",
    "        xval_dir, cross_validator.targets_base\n",
    "    ), \"r\"\n",
    ") as f:\n",
    "    targets = np.array(json.load(f))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataset of every split.\n",
    "targets_test = np.take(\n",
    "    targets,\n",
    "    indices_test,\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert targets_test.shape == predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the classes are balanced.\n",
    "Counter(targets.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy over training/test splits.\n",
    "accuracy = (\n",
    "    (targets_test == predictions).sum(axis=1)\n",
    "    / targets_test.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Accuracy: {:.4g}% ± {:.4g}%\".format(\n",
    "        np.mean(accuracy) * 100.,\n",
    "        np.std(accuracy) * 100.\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
